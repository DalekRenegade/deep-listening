{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workbook 4 - Implementing Salamon and Bello's Convolutional Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Keras/Tensorflow implementation of the 5-layer CNN described in Salamon and Bello's paper (https://arxiv.org/pdf/1608.04363.pdf).\n",
    "\n",
    "The feature extraction process is based on example code posted by Aaqib Saeed:\n",
    "http://aqibsaeed.github.io/2016-09-24-urban-sound-classification-part-2/\n",
    "\n",
    "First, import the libraries. As with the earlier notebooks, the audio processing is handled by a library called librosa, if you haven't already installed it on your local system, do that with: pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a powerful computer, and don't mind the training process taking longer, you can set the all_folds flag to true - which will create a single large training set of 43722 examples, using the first 8 folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = \"data/us8k-np-cnn\"\n",
    "\n",
    "# this will aggregate all the training data \n",
    "def load_all_folds(): \n",
    "    subsequent_fold = False\n",
    "    for k in range(1,9):\n",
    "        fold_name = 'fold' + str(k)\n",
    "        print \"\\nAdding \" + fold_name\n",
    "        feature_file = os.path.join(data_dir, fold_name + '_x.npy')\n",
    "        labels_file = os.path.join(data_dir, fold_name + '_y.npy')\n",
    "        loaded_features = np.load(feature_file)\n",
    "        loaded_labels = np.load(labels_file)\n",
    "        print \"New Features: \", loaded_features.shape\n",
    "\n",
    "        if subsequent_fold:\n",
    "            train_x = np.concatenate((features, loaded_features))\n",
    "            train_y = np.concatenate((labels, loaded_labels))\n",
    "        else:\n",
    "            train_x = loaded_features\n",
    "            train_y = loaded_labels\n",
    "            subsequent_fold = True\n",
    "        \n",
    "    # use the penultimate fold for validation\n",
    "    valid_fold_name = 'fold9'\n",
    "    feature_file = os.path.join(data_dir, valid_fold_name + '_x.npy')\n",
    "    labels_file = os.path.join(data_dir, valid_fold_name + '_y.npy')\n",
    "    valid_x = np.load(feature_file)\n",
    "    valid_y = np.load(labels_file) \n",
    "\n",
    "    # and use the last fold for testing\n",
    "    test_fold_name = 'fold10'\n",
    "    feature_file = os.path.join(data_dir, test_fold_name + '_x.npy')\n",
    "    labels_file = os.path.join(data_dir, test_fold_name + '_y.npy')\n",
    "    test_x = np.load(feature_file)\n",
    "    test_y = np.load(labels_file)\n",
    "    \n",
    "\n",
    "# this is used to load the folds incrementally\n",
    "def load_folds(folds):\n",
    "    subsequent_fold = False\n",
    "    for k in range(len(folds)):\n",
    "        fold_name = 'fold' + str(folds[k])\n",
    "        feature_file = os.path.join(data_dir, fold_name + '_x.npy')\n",
    "        labels_file = os.path.join(data_dir, fold_name + '_y.npy')\n",
    "        loaded_features = np.load(feature_file)\n",
    "        loaded_labels = np.load(labels_file)\n",
    "        print fold_name, \"features: \", loaded_features.shape\n",
    "\n",
    "        if subsequent_fold:\n",
    "            features = np.concatenate((features, loaded_features))\n",
    "            labels = np.concatenate((labels, loaded_labels))\n",
    "        else:\n",
    "            features = loaded_features\n",
    "            labels = loaded_labels\n",
    "            subsequent_fold = True\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Convolutional Neural Network with Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the imports we need and a few configuration variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2, activity_l2\n",
    "\n",
    "frames = 41\n",
    "bands = 60\n",
    "feature_size = bands * frames #60x41\n",
    "num_channels = 2\n",
    "num_labels = 10 # test_y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method defines some evaluation metrics that will be used to evaluate the performance of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    y_prob = model.predict_proba(test_x, verbose=0)\n",
    "    y_pred = np_utils.probas_to_classes(y_prob)\n",
    "    y_true = np.argmax(test_y, 1)\n",
    "\n",
    "    roc = roc_auc_score(test_y, y_prob)\n",
    "    print \"ROC:\",  round(roc,3)\n",
    "\n",
    "    # evaluate the model\n",
    "    score, accuracy = model.evaluate(test_x, test_y, batch_size=32)\n",
    "    print(\"\\nAccuracy = {:.2f}\".format(accuracy))\n",
    "\n",
    "    # the F-score gives a similiar value to the accuracy score, but useful for cross-checking\n",
    "    p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    print \"F-Score:\", round(f,2)\n",
    "    \n",
    "    return roc, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method contains the code that defines the successive layers of our convolutional neural network (CNN) described in this paper by Salamon and Bello: https://arxiv.org/pdf/1608.04363.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    # input: 60x41 data frames with 2 channels => (60,41,2) tensors\n",
    "\n",
    "    # filters of size 3x3 - paper describes using 5x5, but their input data is 128x128\n",
    "    f_size = 3\n",
    "\n",
    "    # Layer 1 - 24 filters with a receptive field of (f,f), i.e. W has the\n",
    "    # shape (24,1,f,f).  This is followed by (4,2) max-pooling over the last\n",
    "    # two dimensions and a ReLU activation function\n",
    "    model.add(Convolution2D(24, f_size, f_size, border_mode='same', input_shape=(bands, frames, num_channels)))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Layer 2 - 48 filters with a receptive field of (f,f), i.e. W has the \n",
    "    # shape (48, 24, f, f). Like L1 this is followed by (4,2) max-pooling \n",
    "    # and a ReLU activation function.\n",
    "    model.add(Convolution2D(48, f_size, f_size, border_mode='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Layer 3 - 48 filters with a receptive field of (f,f), i.e. W has the\n",
    "    # shape (48, 48, f, f). This is followed by a ReLU but no pooling.\n",
    "    model.add(Convolution2D(48, f_size, f_size, border_mode='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # flatten output into a single dimension, let Keras do shape inference\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Layer 4 - a fully connected NN layer of 64 hidden units, L2 penalty of 0.001\n",
    "    model.add(Dense(64, W_regularizer=l2(0.001)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Layer 5 - an output layer with one output unit per class, with L2 penalty, \n",
    "    # followed by a softmax activation function\n",
    "    model.add(Dense(num_labels, W_regularizer=l2(0.001)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # create an optimiser\n",
    "    adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    # compile and fit model, reduce epochs if you want a result faster\n",
    "    # the validation set is used to identify parameter settings (epoch) that achieves \n",
    "    # the highest classification accuracy\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=\"adamax\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the training process, it will create a fresh model for each trial, load the next fold of input data, fit it to the model and evaluate the accuracy achieved. When all the input data has been used, we can calculate the average accuracy for all the folds. The parameters used here have been chosen to allow computation to run on a reasonably powered laptop in less than 10 minutes. When running it on an 8-core high-memory cloud instance, more epochs and larger training sets can be used, this will produce greater prediction accuracy, but come at the cost of much greater training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Train on (1, 2, 3) Validate on 4 Test on 5 ***\n",
      "fold1 features:  (5446, 60, 41, 2)\n",
      "fold2 features:  (5388, 60, 41, 2)\n",
      "fold3 features:  (5852, 60, 41, 2)\n",
      "fold4 features:  (6048, 60, 41, 2)\n",
      "fold5 features:  (5689, 60, 41, 2)\n",
      "Building model...\n",
      "Training model...\n",
      "Train on 16686 samples, validate on 6048 samples\n",
      "Epoch 1/2\n",
      "16686/16686 [==============================] - 58s - loss: 2.2561 - acc: 0.1844 - val_loss: 2.0276 - val_acc: 0.3431\n",
      "Epoch 2/2\n",
      "16686/16686 [==============================] - 73s - loss: 2.0727 - acc: 0.2622 - val_loss: 1.8534 - val_acc: 0.4162\n",
      "Evaluating model...\n",
      "ROC: 0.747\n",
      "5689/5689 [==============================] - 8s     \n",
      "\n",
      "Accuracy = 0.28\n",
      "F-Score: 0.28\n",
      "\n",
      "*** Train on (2, 3, 4) Validate on 5 Test on 6 ***\n",
      "fold2 features:  (5388, 60, 41, 2)\n",
      "fold3 features:  (5852, 60, 41, 2)\n",
      "fold4 features:  (6048, 60, 41, 2)\n",
      "fold5 features:  (5689, 60, 41, 2)\n",
      "fold6 features:  (5080, 60, 41, 2)\n",
      "Building model...\n",
      "Training model...\n",
      "Train on 17288 samples, validate on 5689 samples\n",
      "Epoch 1/2\n",
      "17288/17288 [==============================] - 59s - loss: 2.2126 - acc: 0.2060 - val_loss: 2.1134 - val_acc: 0.2304\n",
      "Epoch 2/2\n",
      "17288/17288 [==============================] - 60s - loss: 1.9776 - acc: 0.2989 - val_loss: 1.8887 - val_acc: 0.3210\n",
      "Evaluating model...\n",
      "ROC: 0.807\n",
      "5080/5080 [==============================] - 7s     \n",
      "\n",
      "Accuracy = 0.34\n",
      "F-Score: 0.34\n",
      "\n",
      "*** Train on (3, 4, 5) Validate on 6 Test on 7 ***\n",
      "fold3 features:  (5852, 60, 41, 2)\n",
      "fold4 features:  (6048, 60, 41, 2)\n",
      "fold5 features:  (5689, 60, 41, 2)\n",
      "fold6 features:  (5080, 60, 41, 2)\n",
      "fold7 features:  (5277, 60, 41, 2)\n",
      "Building model...\n",
      "Training model...\n",
      "Train on 17589 samples, validate on 5080 samples\n",
      "Epoch 1/2\n",
      "17589/17589 [==============================] - 59s - loss: 2.2819 - acc: 0.1758 - val_loss: 2.1719 - val_acc: 0.1787\n",
      "Epoch 2/2\n",
      "17589/17589 [==============================] - 59s - loss: 2.0719 - acc: 0.2655 - val_loss: 1.9971 - val_acc: 0.3297\n",
      "Evaluating model...\n",
      "ROC: 0.788\n",
      "5277/5277 [==============================] - 7s     \n",
      "\n",
      "Accuracy = 0.28\n",
      "F-Score: 0.28\n",
      "\n",
      "Average R.O.C: 0.781\n",
      "Average Accuracy: 0.303\n"
     ]
    }
   ],
   "source": [
    "all_folds = False\n",
    "av_acc = 0.\n",
    "av_roc = 0.\n",
    "num_folds = 0\n",
    "\n",
    "# as we use two folds for training, there are 9 possible trails rather than 10\n",
    "max_trials = 3\n",
    "\n",
    "# earlystopping ends training when the validation loss stops improving\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "\n",
    "if all_folds:\n",
    "    load_all_folds()\n",
    "    model.fit(train_x, train_y, validation_data=(valid_x, valid_y), callbacks=[earlystop], batch_size=32, nb_epoch=1)\n",
    "else:\n",
    "    # use folds incrementally\n",
    "    for f in range(1,max_trials+1):\n",
    "        num_folds += 1\n",
    "        v = f + 3\n",
    "        if v > 10: v = 1\n",
    "        t = v + 1\n",
    "        if t > 10: t = 1\n",
    "        \n",
    "        print \"\\n*** Train on\", (f,f+1,f+2), \"Validate on\", v, \"Test on\", t, \"***\"\n",
    "    \n",
    "        # load two folds for training data\n",
    "        train_x, train_y = load_folds([f,f+1,f+2])\n",
    "    \n",
    "        # load one fold for validation\n",
    "        valid_x, valid_y = load_folds([v])\n",
    "    \n",
    "        # load one fold for testing\n",
    "        test_x, test_y = load_folds([t])\n",
    "        \n",
    "        num_labels = test_y.shape[1]\n",
    "        \n",
    "        print(\"Building model...\")\n",
    "        model = build_model()\n",
    "\n",
    "        # now fit the model to the training data, evaluating loss against the validation data\n",
    "        print(\"Training model...\")\n",
    "        model.fit(train_x, train_y, validation_data=(valid_x, valid_y), callbacks=[earlystop], batch_size=64, nb_epoch=2)\n",
    "        \n",
    "        \n",
    "        # now evaluate the trained model against the unseen test data\n",
    "        print(\"Evaluating model...\")\n",
    "        roc, acc = evaluate(model)\n",
    "        av_roc += roc\n",
    "        av_acc += acc\n",
    "    \n",
    "print '\\nAverage R.O.C:', round(av_roc/max_trials, 3)\n",
    "print 'Average Accuracy:', round(av_acc/max_trials, 3)\n",
    "\n",
    "# using all folds: best ROC = 0.91, f-score = 0.592 (50 epochs)\n",
    "# using 2 folds: average ROC = 0.792, average f-score = 0.335"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save time, once trained, a model can be saved and reloaded to generate predictions. The following cell also shows a summary of the CNN we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_14 (Convolution2D) (None, 60, 41, 24)    456         convolution2d_input_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_9 (MaxPooling2D)    (None, 15, 20, 24)    0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 15, 20, 24)    0           maxpooling2d_9[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 15, 20, 48)    10416       activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_10 (MaxPooling2D)   (None, 3, 10, 48)     0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 3, 10, 48)     0           maxpooling2d_10[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 1, 8, 48)      20784       activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 1, 8, 48)      0           convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 384)           0           activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 64)            24640       flatten_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 64)            0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)             (None, 64)            0           activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 10)            650         dropout_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)             (None, 10)            0           dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 10)            0           dropout_11[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 56946\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#filepath = \"models/salamon-cnn-model.h5\"\n",
    "#model.save(filepath)\n",
    "print model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pretrained model has been supplied, enabling us to run predictions without creating and training a model from scratch, if you want to use it, run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold10 features:  (5218, 60, 41, 2)\n",
      "ROC: 0.91\n",
      "5216/5218 [============================>.] - ETA: 0s\n",
      "Accuracy = 0.59\n",
      "F-Score: 0.59\n",
      "\n",
      "Model R.O.C: 0.91\n",
      "Model Accuracy: 0.592\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_filepath = \"models/salamon-cnn-model.h5\"\n",
    "model = load_model(model_filepath)\n",
    "\n",
    "# model has never seen fold 10, so use that for testing\n",
    "test_x, test_y = load_folds([10])\n",
    "roc, acc = evaluate(model)\n",
    "print '\\nModel R.O.C:', round(roc, 3)\n",
    "print 'Model Accuracy:', round(acc, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saved model achieves an accuracy of 59%, and represents some of the best performance I've achieved with this particular neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_matrix\n",
      "           aircon   horn  child    dog  drill engine    gun hammer  siren  music\n",
      "    aircon    514      0      9      0      1     40      0     70      8     58\n",
      "      horn      6     65     12      3      2      5      0      3      1     38\n",
      "     child      9      2    442    102     14      3      1      0     43     76\n",
      "       dog     13      5    101    279     12     16      0      0     27     62\n",
      "     drill     31      3     26      4    290     43      0     67     66     93\n",
      "    engine     43      0    157      0     15    366      0      9      0     50\n",
      "       gun      0      0      5     18      3      1     45      0      0      0\n",
      "    hammer      6      1     16      0    149      6      0    399      0     11\n",
      "     siren     53     11    164     40     14     11      0      0    256      4\n",
      "     music     43     11    102      0     65      2      0     29     14    434\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = [\"aircon\",\"horn\",\"child\",\"dog\",\"drill\",\"engine\",\"gun\",\"hammer\",\"siren\",\"music\"]\n",
    "print \"Confusion_matrix\"\n",
    "y_prob = model.predict_proba(test_x, verbose=0)\n",
    "y_pred = np_utils.probas_to_classes(y_prob)\n",
    "y_true = np.argmax(test_y, 1)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels]+[5]) # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print \"    \" + empty_cell,\n",
    "    for label in labels: \n",
    "        print \"%{0}s\".format(columnwidth) % label,\n",
    "    print\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print \"    %{0}s\".format(columnwidth) % label1,\n",
    "        for j in range(len(labels)): \n",
    "            cell = \"%{0}s\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print cell,\n",
    "        print\n",
    "    \n",
    "print_cm(cm, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----  air conditioner -----\n",
      "Top guess:  air conditioner  ( 0.914 )\n",
      "2nd guess:  siren  ( 0.02 )\n",
      "\n",
      "-----  car horn -----\n",
      "Top guess:  car horn  ( 0.873 )\n",
      "2nd guess:  street music  ( 0.066 )\n",
      "\n",
      "-----  children playing -----\n",
      "Top guess:  children playing  ( 0.306 )\n",
      "2nd guess:  street music  ( 0.199 )\n",
      "\n",
      "-----  dog bark -----\n",
      "Top guess:  dog bark  ( 0.652 )\n",
      "2nd guess:  children playing  ( 0.244 )\n",
      "\n",
      "-----  drilling -----\n",
      "Top guess:  drilling  ( 0.595 )\n",
      "2nd guess:  jackhammer  ( 0.103 )\n",
      "\n",
      "-----  engine idling -----\n",
      "Top guess:  engine idling  ( 0.876 )\n",
      "2nd guess:  street music  ( 0.033 )\n",
      "\n",
      "-----  gun shot -----\n",
      "Top guess:  gun shot  ( 0.621 )\n",
      "2nd guess:  drilling  ( 0.087 )\n",
      "\n",
      "-----  jackhammer -----\n",
      "Top guess:  jackhammer  ( 0.794 )\n",
      "2nd guess:  street music  ( 0.041 )\n",
      "\n",
      "-----  siren -----\n",
      "Top guess:  siren  ( 0.97 )\n",
      "2nd guess:  street music  ( 0.013 )\n",
      "\n",
      "-----  street music -----\n",
      "Top guess:  street music  ( 0.729 )\n",
      "2nd guess:  car horn  ( 0.056 )\n"
     ]
    }
   ],
   "source": [
    "sound_file_paths = [\"aircon.wav\", \"carhorn.wav\", \"play.wav\", \"dogbark.wav\", \"drill.wav\",\n",
    "                    \"engine.wav\",\"gunshots.wav\",\"jackhammer.wav\",\"siren.wav\",\"music.wav\"]\n",
    "sound_names = [\"air conditioner\",\"car horn\",\"children playing\",\"dog bark\",\"drilling\",\"engine idling\",\n",
    "               \"gun shot\",\"jackhammer\",\"siren\",\"street music\"]\n",
    "parent_dir = 'samples/us8k/'\n",
    "\n",
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield start, start + window_size\n",
    "        start += (window_size / 2)\n",
    "\n",
    "def extract_features_array(filename, bands = 60, frames = 41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    log_specgrams = []\n",
    "    sound_clip,s = librosa.load(filename)        \n",
    "    for (start,end) in windows(sound_clip,window_size):\n",
    "        if(len(sound_clip[start:end]) == window_size):\n",
    "            signal = sound_clip[start:end]\n",
    "            melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "            logspec = librosa.logamplitude(melspec)\n",
    "            logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "            log_specgrams.append(logspec)\n",
    "            \n",
    "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
    "    for i in range(len(features)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# create predictions for each of the sound classes\n",
    "for s in range(len(sound_names)):\n",
    "\n",
    "    print \"\\n----- \", sound_names[s], \"-----\"\n",
    "    # load audio file and extract features\n",
    "    predict_file = parent_dir + sound_file_paths[s]\n",
    "    predict_x = extract_features_array(predict_file)\n",
    "    \n",
    "    # generate prediction, passing in just a single row of features\n",
    "    predictions = model.predict(predict_x)\n",
    "    \n",
    "    if len(predictions) == 0: \n",
    "        print \"No prediction\"\n",
    "        continue\n",
    "        \n",
    "    #for i in range(len(predictions[0])):\n",
    "    #    print sound_names[i], \"=\", round(predictions[0,i] * 100, 1)\n",
    "    \n",
    "    # get the indices of the top 2 predictions, invert into descending order\n",
    "    ind = np.argpartition(predictions[0], -2)[-2:]\n",
    "    ind[np.argsort(predictions[0][ind])]\n",
    "    ind = ind[::-1]\n",
    "    \n",
    "    print \"Top guess: \", sound_names[ind[0]], \" (\",round(predictions[0,ind[0]],3),\")\"\n",
    "    print \"2nd guess: \", sound_names[ind[1]], \" (\",round(predictions[0,ind[1]],3),\")\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Although this model can correctly identify all 10 samples, the accuracy across the entire test set is still only 59%. From my investigations, there do seem to be certain recordings the classifier finds difficult to identify correctly, these tend to be the very short recordings, 1 or 2 seconds long, and recordings that consist of only rapid repetitive noise. \n",
    "\n",
    "I managed to get slightly better results with the CNN than my best FFN, an ROC of 0.91 with the CNN, compared to 0.89 with my FFN. My max f-score accuracy for both is about 60%. Getting higher results proved difficult, and there may be diminishing returns for effort given the constraints of the data set, (8000 samples isn't a huge amount, and it does include some repetition of same sound source).\n",
    "\n",
    "In their paper Salamon and Bello report an accuracy of 73% - but it's worth bearing in mind that their CNN is optimised for a different feature extraction process. I was feeding my implementation of their CNN features extracted with Piczak's method.\n",
    "\n",
    "To summarise then, I've managed to implement a general audio classifier capable of distinguishing between different sources of sound. Next, I intend to investigate whether this classifier will be able to effectively recognise some very different sources of sound: birdsong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
